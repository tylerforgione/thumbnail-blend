# -*- coding: utf-8 -*-
"""thumbnails.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y0Uhqr-VrpLjTdnyr8X-_WmN_BsXWJ3Y
"""

!pip install scrapetube

import scrapetube
from PIL import Image, ImageOps
import requests
from io import BytesIO
from itertools import islice
import numpy as np
from tqdm import tqdm
import cv2

def resize_with_padding(img, target_size=(1280, 720)):
    target_w, target_h = target_size
    img_ratio = img.width / img.height
    target_ratio = target_w / target_h

    # round up or down depending on aspect ratio of given and target images
    if img_ratio > target_ratio:
        new_w = target_w
        new_h = round(target_w / img_ratio)
    else:
        new_h = target_h
        new_w = round(target_h * img_ratio)

    # resize the image with 0 padding
    img_resized = img.resize((new_w, new_h), Image.LANCZOS)
    new_img = Image.new("RGB", target_size, (0, 0, 0))
    new_img.paste(img_resized, ((target_w - new_w)//2, (target_h - new_h)//2))
    return new_img

def align_images(base_img, img_to_align):
    # Convert to grayscale
    base_gray = cv2.cvtColor(np.array(base_img), cv2.COLOR_RGB2GRAY)
    align_gray = cv2.cvtColor(np.array(img_to_align), cv2.COLOR_RGB2GRAY)

    # ORB feature detector
    orb = cv2.ORB_create(500)
    kp1, des1 = orb.detectAndCompute(base_gray, None)
    kp2, des2 = orb.detectAndCompute(align_gray, None)

    # Match features
    bf = cv2.BFMatcher(cv2.NORM_HAMMING, crossCheck=True)
    matches = bf.match(des1, des2)
    matches = sorted(matches, key=lambda x: x.distance)
    if len(matches) < 4:
        return img_to_align  # fallback if not enough matches

    src_pts = np.float32([kp2[m.trainIdx].pt for m in matches[:10]]).reshape(-1, 1, 2)
    dst_pts = np.float32([kp1[m.queryIdx].pt for m in matches[:10]]).reshape(-1, 1, 2)

    # Compute affine transform
    M, _ = cv2.estimateAffinePartial2D(src_pts, dst_pts)
    aligned = cv2.warpAffine(np.array(img_to_align), M, (base_img.width, base_img.height))
    return Image.fromarray(aligned)

def blend_thumbnails(channel_id, align=False):
  # get all videos from given channel
  videos = scrapetube.get_channel(channel_id)
  sum_image = np.zeros((720, 1280, 3), dtype=np.float64)
  count = 0
  videos = list(islice(videos, 100))
  base_img = None

  for video in tqdm(videos, "Blending images into one: "):
    # sometimes a video doesn't have a maxresdefault
    for suffix in ["maxresdefault.jpg", "mqdefault.jpg"]:
      img_url = f"http://img.youtube.com/vi/{video['videoId']}/{suffix}"
      # raise exception if error when getting thumbnail (typically 404)
      try:
        resp = requests.get(img_url, timeout=5)
        resp.raise_for_status()
        # convert jpg to rgb
        img = Image.open(BytesIO(resp.content)).convert("RGB")
        img = resize_with_padding(img, (1280, 720))

        # NOTE: only align if thumbnails are very similar
        if align == True:
          if base_img is None:
            base_img = img
          else:
            img = align_images(base_img, img)

        sum_image += np.array(img, dtype=np.float64)
        count += 1
        break
      except Exception as e:
        continue

  if count == 0:
    raise ValueError("No valid thumbnails")

  average_image = sum_image / count
  normalized = np.clip(average_image / 255.0, 0, 1)
  img_to_show = (normalized * 255).astype(np.uint8)
  img_pil = Image.fromarray(img_to_show)
  img_pil.save("blended_thumbnails.jpg")

blend_thumbnails("UC7_YxT-KID8kRbqZo7MyscQ", True)

img = Image.open("blended_thumbnails.jpg").convert("RGB")
img = ImageOps.autocontrast(img, cutoff=2.0)
img.save("test.jpg")